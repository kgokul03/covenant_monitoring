{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0069639-85a2-407d-a7a8-f519fb837a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kawin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import ollama\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c0cf73-8960-4be8-b1d1-111e429d66de",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 300\n",
    "CYAN = '\\033[96m'\n",
    "NEON_GREEN = '\\033[92m'\n",
    "RESET_COLOR = '\\033[0m'\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1',\n",
    "    api_key='llama3.2:3b'\n",
    ")\n",
    "\n",
    "class CreditAgreementMetadata(BaseModel):\n",
    "    issuer: Optional[str] = None\n",
    "    administrative_agent: Optional[str] = None\n",
    "    underwriter: Optional[str] = None\n",
    "    agreement_date: Optional[str] = Field(None, description=\"Agreement date in YYYY-MM-DD format\")\n",
    "\n",
    "class CovenantDetail(BaseModel):\n",
    "    title: str\n",
    "    description: str\n",
    "\n",
    "class Covenant(BaseModel):\n",
    "    items: List[CovenantDetail]\n",
    "\n",
    "def prompts_and_execution(content, isMetaData):\n",
    "    if isMetaData:\n",
    "        prompt = f\"\"\"\n",
    "            ### System Instruction:  \n",
    "            You are an AI model tasked with extracting specific financial details from documents. **Follow these instructions precisely:**  \n",
    "            - Return the output in **strict JSON format** with the specified keys.  \n",
    "            - If a key's information is missing, return an **empty string (\"\")** instead of omitting the key.  \n",
    "            - Do **not** add extra text, explanations, or additional keys\n",
    "            - **Don't need your <think> tags in the answer**\n",
    "            \n",
    "            ### **Extraction Task:**  \n",
    "            Extract the following details from the provided document:  \n",
    "            \n",
    "            - **issuer**: The entity issuing the agreement.  \n",
    "            - **administrative_agent**: The administrative agent managing the agreement.  \n",
    "            - **underwriter**: The underwriter, bookrunner, or lead arranger.  \n",
    "            - **agreement_date**: The agreement date in **YYYY-MM-DD** format.  \n",
    "            \n",
    "            ### **Document Content:**  \n",
    "            {content}\n",
    "            \"\"\"\n",
    "    else:\n",
    "        prompt = f\"\"\"\n",
    "            ### System Instruction:  \n",
    "            You are an helpful AI assistant tasked with extracting specific financial details from documents. **Follow these instructions precisely:**  \n",
    "            - Return the output in **strict JSON format** with the **specified keys** as mentioned in extraction template \n",
    "            - No Extra information is needed \n",
    "            - no triple single quotes needed in output to represent json output \n",
    "            - add to list only if you have data for title and description. Don't add if you have empty description from the document\n",
    "            \n",
    "            ### **Extraction Task:**  \n",
    "            Extract the list of covenants, terms & conditions and details from the provided document with the list of covenant type as key named 'title' and its summary/description of the respective covenant type as value named 'description' in around 30 words.\n",
    "            \n",
    "            [\n",
    "                {{\n",
    "                    \"title\": \"<covenant type 1>\" **In 2-5 word**\n",
    "                    \"description\": \"<description of covenant type 1>\" **In 30 words**\n",
    "                }},\n",
    "                {{\n",
    "                    \"title\": \"<covenant type 2>\" **In 2-5 words**\n",
    "                    \"description\": \"<description of covenant type 2>\" **In 30 words**\n",
    "                }},\n",
    "                {{\n",
    "                    \"title\": \"<covenant type 3>\" **In 2-5 words**\n",
    "                    \"description\": \"<description of covenant type 3>\" **In 30 words**\n",
    "                }},\n",
    "                ... **TO BE CONTINUED**\n",
    "            ]\n",
    "\n",
    "            ### **Document Content:**  \n",
    "            {content}\n",
    "            \"\"\"\n",
    "    # Send the structured prompt to Ollama\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3.2:3b\",  # Ensure this matches your model name\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    # Extract the text response from the model\n",
    "    response_text = response.choices[0].message.content\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c489383-5f85-49d9-87a5-4499d5748d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_legal_structure(text):\n",
    "    \"\"\"Check if text matches the legal-style structure of Articles and Sections.\"\"\"\n",
    "    pattern = r\"(Article\\s+[IVXLCDM]+\\s+.*\\d+|Section\\s+\\d+\\.\\d+\\s+.*\\d+)\"\n",
    "    return re.search(pattern, text) is not None\n",
    "    \n",
    "def clean_text(text):\n",
    "    # Remove URLs and SEC archive references\n",
    "    text = re.sub(r'https?://\\S+|sec\\.gov/Archives/\\S+', '', text)\n",
    "    # Remove metadata like EX-10.1 and timestamps\n",
    "    text = re.sub(r'EX-\\d+\\.\\d+.*', '', text)\n",
    "    text = re.sub(r'\\d+/\\d+/\\d+, \\d+:\\d+ \\w+', '', text)\n",
    "    # Remove trailing page numbers (e.g., 1/274)\n",
    "    text = re.sub(r'\\b\\d+/\\d+\\b', '', text)\n",
    "\n",
    "    if is_legal_structure(text):\n",
    "        return \"\"\n",
    "\n",
    "    # Remove extra spaces and newlines\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def getDataFromPdf(pdf_path):\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_path)\n",
    "    text_list = []\n",
    "    for page in pdf_reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        text_list.append(clean_text(page_text))\n",
    "    return \" \".join(text_list)  # Join all pages with a space\n",
    "\n",
    "def getMetaDataFromPdf(pdf_path):\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_path)\n",
    "    text = pdf_reader.pages[0].extract_text() if pdf_reader.pages else None\n",
    "    return clean_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f340b2d7-159c-4480-b973-0987abb4dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Efficient semantic embeddings\n",
    "\n",
    "def prepareChunks(text, chunk_size=CHUNK_SIZE, output_file=\"vault.txt\", similarity_threshold=0.6):\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Use spaCy for sentence segmentation\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_chunk_embedding = None  # Store embeddings for semantic similarity checks\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_embedding = embedder.encode(sentence, convert_to_tensor=True)\n",
    "\n",
    "        # If adding a sentence exceeds chunk size OR it's semantically different → Start a new chunk\n",
    "        if (sum(len(s) for s in current_chunk) + len(sentence) + 1 > chunk_size or\n",
    "                (current_chunk_embedding is not None and \n",
    "                 util.pytorch_cos_sim(current_chunk_embedding, sentence_embedding).item() < similarity_threshold)):\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [sentence]\n",
    "            current_chunk_embedding = sentence_embedding\n",
    "        else:\n",
    "            current_chunk.append(sentence)\n",
    "            # Update chunk embedding as average of existing embeddings\n",
    "            current_chunk_embedding = sentence_embedding if current_chunk_embedding is None else \\\n",
    "                                      (current_chunk_embedding + sentence_embedding) / 2\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    # Save chunks to a file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as vault_file:\n",
    "        vault_file.write(\"\\n\\n\".join(chunks))  # Efficient file writing\n",
    "\n",
    "    print(f\"PDF content stored in {output_file} with semantic chunking.\")\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "405bfa3c-614d-4c79-a806-43c5e84cb5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareEmbeddings(chunks):\n",
    "    print(NEON_GREEN + \"Generating embeddings for the vault content...\" + RESET_COLOR)\n",
    "    vault_embeddings = []\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            response = ollama.embeddings(model='nomic-embed-text', prompt=chunk)\n",
    "            embedding = response.get(\"embedding\")\n",
    "            if embedding:  # Ensure embedding is not None\n",
    "                vault_embeddings.append(embedding)\n",
    "            else:\n",
    "                print(f\"Skipping invalid embedding for content: {chunk.strip()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to generate embedding for content: {chunk.strip()}. Error: {e}\")\n",
    "\n",
    "    if not vault_embeddings:\n",
    "        print(\"No valid embeddings generated. Exiting...\")\n",
    "        exit(1)\n",
    "    return vault_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8a8f9c3-ec11-4dc4-a74e-2852765bdfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertEmbeddingsToTensor(vault_embeddings):\n",
    "    # Ensure all embeddings have the same size\n",
    "    embedding_size = len(vault_embeddings[0])\n",
    "    if any(len(e) != embedding_size for e in vault_embeddings):\n",
    "        print(\"Embedding size mismatch detected. Skipping invalid embeddings...\")\n",
    "        vault_embeddings = [e for e in vault_embeddings if len(e) == embedding_size]\n",
    "\n",
    "    # Convert to tensor\n",
    "    vault_embeddings_tensor = torch.tensor(vault_embeddings)\n",
    "    print(\"Embeddings for each line in the vault:\")\n",
    "    print(vault_embeddings_tensor)\n",
    "    return vault_embeddings_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a109c95c-1461-4dd0-ba2b-b56089e936e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_context(rewritten_input, vault_embeddings, vault_content, top_k=15):\n",
    "    if not rewritten_input.strip():\n",
    "        print(\"Rewritten input is empty. Skipping context retrieval.\")\n",
    "        return []\n",
    "\n",
    "    if vault_embeddings.nelement() == 0:  # Check if the tensor has any elements\n",
    "        print(\"Vault embeddings are empty. Skipping context retrieval.\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        input_embedding = ollama.embeddings(model='nomic-embed-text', prompt=rewritten_input)[\"embedding\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to generate input embedding. Error: {e}\")\n",
    "        return []\n",
    "\n",
    "    if not input_embedding:\n",
    "        print(\"Input embedding is invalid. Skipping context retrieval.\")\n",
    "        return []\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cos_scores = torch.cosine_similarity(torch.tensor(input_embedding).unsqueeze(0), vault_embeddings)\n",
    "\n",
    "    # Adjust top_k if needed\n",
    "    top_k = min(top_k, len(cos_scores))\n",
    "    top_indices = torch.topk(cos_scores, k=top_k)[1].tolist()\n",
    "\n",
    "    # Retrieve relevant context\n",
    "    relevant_context = [vault_content[idx].strip() for idx in top_indices]\n",
    "    return relevant_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cfcc7bc-7398-49db-b277-6e2331863127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelevantEmbeddings(query, embeddings, content):\n",
    "    relevant_context = get_relevant_context(query, embeddings, content)\n",
    "    if relevant_context:\n",
    "        context_str = \"\\n\".join(relevant_context)\n",
    "        print(\"Context Pulled from Documents: \\n\\n\" + CYAN + context_str + RESET_COLOR)\n",
    "    else:\n",
    "        print(CYAN + \"No relevant context found.\" + RESET_COLOR)\n",
    "\n",
    "    return prompts_and_execution(context_str, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17edeed2-d1c3-40a9-9bff-176dcd12fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = getDataFromPdf(\"./Example_2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbe04036-bdeb-44ef-8986-8608bc7b683e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditAgreementMetadata(issuer='JPMORGAN CHASE BANK, N.A.', administrative_agent='JPMORGAN CHASE BANK, N.A.', underwriter='JPMORGAN CHASE BANK, N.A.', agreement_date='2023-07-26')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_page_content = getMetaDataFromPdf(\"./Example_2.pdf\")\n",
    "json_response = prompts_and_execution(first_page_content, True)\n",
    "json_response = re.sub(r'<think>.*?</think>','',json_response)\n",
    "\n",
    "def parse_json_response(response_text):\n",
    "    \"\"\"\n",
    "    Parses the JSON response and maps it to the CreditAgreementDetails model.\n",
    "    \"\"\"\n",
    "    data = json.loads(response_text)  # Convert JSON string to Python dictionary\n",
    "    date_obj = None\n",
    "    # Normalize keys to match the Pydantic model\n",
    "    mapped_details = {\n",
    "        \"issuer\": data.get(\"issuer\"),\n",
    "        \"administrative_agent\": data.get(\"administrative_agent\"),\n",
    "        \"underwriter\": data.get(\"underwriter\"),\n",
    "        \"agreement_date\": data.get(\"agreement_date\")\n",
    "    }\n",
    "    return CreditAgreementMetadata(**mapped_details)\n",
    "\n",
    "parse_json_response(json_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a81efca-e13b-4a45-afc2-f74bcaef1398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"issuer\": \"JPMORGAN CHASE BANK, N.A.\", \"administrative_agent\": \"JPMORGAN CHASE BANK, N.A.\", \"underwriter\": \"JPMORGAN CHASE BANK, N.A.\", \"agreement_date\": \"2023-07-26\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CreditAgreementMetadata(issuer='JPMORGAN CHASE BANK, N.A.', administrative_agent='JPMORGAN CHASE BANK, N.A.', underwriter='JPMORGAN CHASE BANK, N.A.', agreement_date='2023-07-26')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response = re.sub(r'<think>.*</think>','',json_response)\n",
    "print(json_response)\n",
    "def parse_json_response(response_text):\n",
    "    \"\"\"\n",
    "    Parses the JSON response and maps it to the CreditAgreementDetails model.\n",
    "    \"\"\"\n",
    "    data = json.loads(response_text)  # Convert JSON string to Python dictionary\n",
    "    date_obj = None\n",
    "    # Normalize keys to match the Pydantic model\n",
    "    mapped_details = {\n",
    "        \"issuer\": data.get(\"issuer\"),\n",
    "        \"administrative_agent\": data.get(\"administrative_agent\"),\n",
    "        \"underwriter\": data.get(\"underwriter\"),\n",
    "        \"agreement_date\": data.get(\"agreement_date\")\n",
    "    }\n",
    "    return CreditAgreementMetadata(**mapped_details)\n",
    "\n",
    "parse_json_response(json_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed98efdb-d3f8-47a9-a79c-959f2b1cfeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF content stored in vault.txt with semantic chunking.\n"
     ]
    }
   ],
   "source": [
    "chunks = prepareChunks(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "068dd19c-5bc2-4331-87af-aed4f6e76f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mGenerating embeddings for the vault content...\u001b[0m\n",
      "Skipping invalid embedding for content: \n"
     ]
    }
   ],
   "source": [
    "embeddings = prepareEmbeddings(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc55d9c0-f1b9-4302-a162-f4fa0f261103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings for each line in the vault:\n",
      "tensor([[ 0.5527,  0.6475, -3.3231,  ..., -1.2179, -0.5984, -0.2288],\n",
      "        [ 0.1551,  1.2223, -3.8140,  ..., -0.8028, -0.9273, -1.1324],\n",
      "        [ 0.0694, -0.3534, -3.4456,  ..., -0.6191, -0.5641, -1.1630],\n",
      "        ...,\n",
      "        [-0.1832,  0.2234, -3.0310,  ..., -1.5724, -1.4899, -0.8560],\n",
      "        [ 0.8140,  1.1958, -3.4786,  ..., -1.3802, -0.8361, -0.2035],\n",
      "        [ 1.0608,  0.4400, -3.2910,  ..., -1.8609, -0.9382,  0.1237]])\n"
     ]
    }
   ],
   "source": [
    "tensor_embedding = convertEmbeddingsToTensor(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bead848-65f8-4bc2-a823-85bddb1319da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(query):\n",
    "    return getRelevantEmbeddings(query, tensor_embedding, chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2702e8db-263e-4c63-9e43-392504951750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Pulled from Documents: \n",
      "\n",
      "\u001b[96m“Final Release Conditions” has the meaning assigned to such term in Section 9.14(c).\n",
      "Each Borrowing (other than a conversion or continuation of any Loans) shall be deemed to constitute a representation and warranty by the Borrower on the date thereof as to the matters specified in paragraphs (a) and (b) of this Section.\n",
      "“Collateral” means any and all property owned, leased or operated by a Person covered by the Collateral Documents and any and all other property of any Loan Party, now existing or hereafter acquired, that may at any time be or become subject to a security interest or Lien in favor of the Administrative Agent, on behalf of itself and the Secured Parties, pursuant to the Collateral Documents to secure the Secured Obligations; provided that the Collateral shall exclude Excluded Assets.\n",
      "Section 9.05 Survival.\n",
      "Notwithstanding anything herein to the contrary, no Intellectual Property that is owned by or licensed to the Borrower or its Subsidiaries that is material to the business of the Borrower and the other Loan Parties, taken as a whole, shall be assigned, transferred, or exclusively licensed or exclusively sublicensed to any Subsidiary that is not a Loan Party or to any Affiliate of the Borrower or any of its Subsidiaries (other than pursuant to a Permitted License).\n",
      "AS DEFINED IN THE IMMEDIATELY PRECEDING PARAGRAPH FURNISHED TO IT PURSUANT TO THIS AGREEMENT MAY INCLUDE MATERIAL NON-PUBLIC INFORMATION CONCERNING THE BORROWER AND ITS RELATED PARTIES OR THEIR RESPECTIVE SECURITIES, AND CONFIRMS THAT IT HAS DEVELOPED COMPLIANCE PROCEDURES REGARDING THE USE OF MATERIAL NON- PUBLIC INFORMATION AND THAT IT WILL HANDLE SUCH MATERIAL NON- PUBLIC INFORMATION IN ACCORDANCE WITH THOSE PROCEDURES AND APPLICABLE LAW, INCLUDING FEDERAL AND STATE SECURITIES LAWS.\n",
      "“Liquidity” means, as of any date of determination, the sum of all Unencumbered Cash.\n",
      "“Loan Documents” means this Agreement (including schedules and exhibits hereto), any promissory notes issued pursuant to Section 2.10(e), the Collateral Documents, the Guaranty, any fee letters, and all other agreements, instruments, documents and certificates identified in Section 4.01 executed and delivered to, or in favor of, the Administrative Agent or any Lenders; provided that Loan Documents shall not include any Banking Services Agreement or Swap Agreement.\n",
      "The Borrower will ensure that any information, including financial statements or other documents (other than any projections, estimates, forecasts and other forward-looking information and information of a general economic or industry-specific nature), furnished by or on behalf of the Borrower or any Subsidiary to the Administrative Agent or the Lenders in connection with this Agreement or any amendment or modification hereof or waiver hereunder, when taken as a whole and after giving effect to all supplements and updates thereto, contains (when furnished) no material misstatement of fact or omits to state any material fact necessary to make the statements therein, in the light of the circumstances under which they were made, not materially misleading (when taken as a whole), and the furnishing of such information shall be deemed to be a representation and warranty by the Borrower on the date thereof as to the matters specified in this Section 5.10.\n",
      "This Agreement may be executed in counterparts (and by different parties hereto on different counterparts), each of which shall constitute an original, but all of which when taken together shall constitute a single contract.\n",
      "“Trade Date” has the meaning assigned to such term in Section 9.04(e)(i).\n",
      "“Securities Act” means the United States Securities Act of 1933.\n",
      "Section 3.02 Authorization; Enforceability.\n",
      "Governing Law; Jurisdiction; Consent to Service of Process.\n",
      "(a) A Subsidiary Guarantor shall automatically be released from its obligations under the Loan Documents upon the consummation of any transaction permitted by this Agreement as a result of which such Subsidiary Guarantor ceases to be a Subsidiary; provided that, if so required by this Agreement, the Required Lenders shall have consented to such transaction and the terms of such consent shall not have provided otherwise.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ques='Extract all the covenant details, its terms and agreements defined in the document'\n",
    "response = get(ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41f3d6df-f8d7-457f-b98d-b96119c11995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n    {\\n        \"title\": \"Covenant Description\",\\n        \"description\": \"Matters specified in paragraphs (a) and (b) of this Section, as a representation and warranty by the Borrower\"\\n    },\\n    {\\n        \"title\": \"Collateral Exclusions\",\\n        \"description\": \"Ex excluded Assets, pursuant to the Collateral Documents to secure the Secured Obligations are excluded from the definition of \\\\\"Collateral\\\\\".\"\\n    }\\n]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b340de8e-1a55-4c78-b4d1-f363e8005fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items=[CovenantDetail(title='Covenant Description', description='Matters specified in paragraphs (a) and (b) of this Section, as a representation and warranty by the Borrower'), CovenantDetail(title='Collateral Exclusions', description='Ex excluded Assets, pursuant to the Collateral Documents to secure the Secured Obligations are excluded from the definition of \"Collateral\".')]\n"
     ]
    }
   ],
   "source": [
    "response = response.replace(\"'''\", \"\")\n",
    "try:\n",
    "    json_data = json.loads(response)  # Convert text to JSON\n",
    "    parsed_response = Covenant(items=json_data)  # Validate with Pydantic\n",
    "    print(parsed_response)\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error: Model did not return valid JSON. Raw output:\")\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to parse response: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae663eaa-4cb4-4403-9312-5b1b1fd881e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
